# üè¢ On-Premise Model Configurations
# Lus√≥fona Internal Infrastructure Models
# 
# These models run on internal Lus√≥fona servers and provide
# local AI capabilities without external dependencies.

model_list:

  # Internal Infrastructure Model - Gemma 2 9B IT (pop06)
  - model_name: gemma-2-9b-it-Lusofona-On-Premise
    litellm_params:
      model: openai/gemma-2-9b-it-Q4_K_L
      api_base: http://192.168.80.6:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: gemma-2-9b-it-Q4_K_L
      host_node: 192.168.80.6

  # Internal Infrastructure Model - Qwen2.5 VL 7B Instruct (pop05)
  - model_name: Qwen2.5-VL-7B-Instruct-Lusofona-On-Premise
    litellm_params:
      model: openai/Qwen2.5-VL-7B-Instruct-Q6_K
      api_base: http://192.168.80.5:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: Qwen2.5-VL-7B-Instruct-Q6_K
      host_node: 192.168.80.5

  # Internal Infrastructure Model - DeepSeek R1 Distill Llama 8B (pop04)
  - model_name: DeepSeek-R1-Distill-Llama-8B-Lusofona-On-Premise
    litellm_params:
      model: openai/DeepSeek-R1-Distill-Llama-8B-Q6_K
      api_base: http://192.168.80.4:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: DeepSeek-R1-Distill-Llama-8B-Q6_K
      host_node: 192.168.80.4

  # Internal Infrastructure Model - Meta Llama 3.1 8B Instruct (pop02)
  - model_name: Meta-Llama-3.1-8B-Instruct-Lusofona-On-Premise
    litellm_params:
      model: openai/Meta-Llama-3.1-8B-Instruct-Q4_K_M
      api_base: http://192.168.80.12:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: Meta-Llama-3.1-8B-Instruct-Q4_K_M
      host_node: 192.168.80.12

  # Internal Infrastructure Model - Gemma 3 4B IT (pop01)
  - model_name: gemma-3-4b-it-Lusofona-On-Premise
    litellm_params:
      model: openai/gemma-3-4b-it-Q8_0
      api_base: http://192.168.80.11:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: gemma-3-4b-it-Q8_0
      host_node: 192.168.80.11 