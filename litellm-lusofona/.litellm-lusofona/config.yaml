model_list:
  # DeepSeek Model Deployments
  - model_name: deepseek-r1-8b
    litellm_params:
      model: openai/deepseek-r1-llama-8b
      api_base: http://192.168.108.161:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: DeepSeek-R1-Distill-Llama-8B-Q6_K
      host_node: 192.168.108.161

  - model_name: deepseek-r1-8b
    litellm_params:
      model: openai/deepseek-r1-llama-8b
      api_base: http://192.168.108.162:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: DeepSeek-R1-Distill-Llama-8B-Q6_K
      host_node: 192.168.108.162

  - model_name: deepseek-r1-8b
    litellm_params:
      model: openai/deepseek-r1-llama-8b
      api_base: http://192.168.108.163:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: DeepSeek-R1-Distill-Llama-8B-Q6_K
      host_node: 192.168.108.163

  # Meta Llama Model Deployments
  - model_name: llama-3.1-8b
    litellm_params:
      model: openai/meta-llama-3-8b
      api_base: http://192.168.108.164:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: Meta-Llama-3.1-8B-Instruct-Q4_K_M
      host_node: 192.168.108.164

  - model_name: llama-3.1-8b
    litellm_params:
      model: openai/meta-llama-3-8b
      api_base: http://192.168.108.165:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: Meta-Llama-3.1-8B-Instruct-Q4_K_M
      host_node: 192.168.108.165

  - model_name: gemma3-4b
    litellm_params:
      model: openai/gemma3:4b
      api_base: http://192.168.108.166:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: gemma3-4b
      host_node: 192.168.108.166

litellm_settings:
  callbacks: ["prometheus"]
  service_callback: ["prometheus_system"]
  drop_params: True
  num_retries: 3
  request_timeout: 30

router_settings:
  routing_strategy: "least-busy"
  redis_host: redis
  redis_port: 6379
  redis_password: your_redis_password
  timeout: 30
  num_retries: 2
