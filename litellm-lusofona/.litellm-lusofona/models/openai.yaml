# openai.yaml
# ðŸ¤– OpenAI Model Configurations - Updated 22-09-2025
# Source: https://platform.openai.com/docs/pricing
# Note: Cached input pricing is represented via `cache_read_input_token_cost` and
#       `cache_creation_input_token_cost` in model_info when applicable.
#
# Web clipping (OpenAI Pricing) - 22-09-2025
# --- BEGIN WEB CLIP ---
# Text tokens (per 1M):
# gpt-5: $1.25 input, $0.125 cached input, $10.00 output
# gpt-5-mini: $0.25 input, $0.025 cached input, $2.00 output
# gpt-5-nano: $0.05 input, $0.005 cached input, $0.40 output
# gpt-4.1: $2.00 input, $0.50 cached input, $8.00 output
# gpt-4.1-mini: $0.40 input, $0.10 cached input, $1.60 output
# gpt-4.1-nano: $0.10 input, $0.025 cached input, $0.40 output
# gpt-4o: $2.50 input, $1.25 cached input, $10.00 output
# gpt-4o-2024-05-13: $5.00 input, - cached input, $15.00 output
# gpt-4o-mini: $0.15 input, $0.075 cached input, $0.60 output
# o1: $15.00 input, $7.50 cached input, $60.00 output
# o1-pro: $150.00 input, - cached input, $600.00 output
# o3: $2.00 input, $0.50 cached input, $8.00 output
# o3-mini: $1.10 input, $0.55 cached input, $4.40 output
# o1-mini: $1.10 input, $0.55 cached input, $4.40 output
# gpt-3.5-turbo: $0.50 input, - cached input, $1.50 output
# Embeddings per 1M: 3-large=$0.13, 3-small=$0.02, ada-002=$0.10
# Image generation: see pricing table (per-image)
# Audio/Other: Whisper=$0.006/min, TTS=$15/$30 per 1M chars
# Built-in tools pricing omitted; refer to source link.
# --- END WEB CLIP ---

model_list:
  # GPT-5 Series - Latest flagship models
  - model_name: OpenAI-GPT-5
    litellm_params:
      model: gpt-5
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.00000125   # $1.25 per 1M input tokens
      cache_read_input_token_cost: 0.000000125   # $0.125 per 1M cached input tokens
      output_cost_per_token: 0.00001     # $10.00 per 1M output tokens
      model_alias: GPT-5
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-5-Mini
    litellm_params:
      model: gpt-5-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 2000000
    model_info:
      input_cost_per_token: 0.00000025   # $0.25 per 1M input tokens
      cache_read_input_token_cost: 0.000000025  # $0.025 per 1M cached input tokens
      output_cost_per_token: 0.000002    # $2.00 per 1M output tokens
      model_alias: GPT-5-Mini
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "standard"

  - model_name: OpenAI-GPT-5-Nano
    litellm_params:
      model: gpt-5-nano
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 3000000
    model_info:
      input_cost_per_token: 0.00000005   # $0.05 per 1M input tokens
      cache_read_input_token_cost: 0.000000005  # $0.005 per 1M cached input tokens
      output_cost_per_token: 0.0000004   # $0.40 per 1M output tokens
      model_alias: GPT-5-Nano
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "budget"

  # GPT-4.1 Series - Advanced reasoning models
  - model_name: OpenAI-GPT-4.1
    litellm_params:
      model: gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.000002     # $2.00 per 1M input tokens
      cache_read_input_token_cost: 0.0000005   # $0.50 per 1M cached input tokens
      output_cost_per_token: 0.000008    # $8.00 per 1M output tokens
      model_alias: GPT-4.1
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-4.1-Mini
    litellm_params:
      model: gpt-4.1-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1500000
    model_info:
      input_cost_per_token: 0.0000004    # $0.40 per 1M input tokens
      cache_read_input_token_cost: 0.0000001   # $0.10 per 1M cached input tokens
      output_cost_per_token: 0.0000016   # $1.60 per 1M output tokens
      model_alias: GPT-4.1-Mini
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "standard"

  # GPT-4o Series - Current flagship models
  - model_name: OpenAI-GPT-4o
    litellm_params:
      model: gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.0000025    # $2.50 per 1M input tokens
      cache_read_input_token_cost: 0.00000125  # $1.25 per 1M cached input tokens
      output_cost_per_token: 0.00001     # $10.00 per 1M output tokens
      model_alias: GPT-4o
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-4o-Mini
    litellm_params:
      model: gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 2000000
    model_info:
      input_cost_per_token: 0.00000015   # $0.15 per 1M input tokens
      cache_read_input_token_cost: 0.000000075  # $0.075 per 1M cached input tokens
      output_cost_per_token: 0.0000006   # $0.60 per 1M output tokens
      model_alias: GPT-4o-Mini
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "standard"

  # GPT-4o Legacy Version
  - model_name: OpenAI-GPT-4o-2024-05-13
    litellm_params:
      model: gpt-4o-2024-05-13
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 500000
    model_info:
      input_cost_per_token: 0.000005     # $5.00 per 1M input tokens
      output_cost_per_token: 0.000015    # $15.00 per 1M output tokens
      model_alias: GPT-4o-Legacy
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "premium"

  # o-Series - Advanced reasoning models
  - model_name: OpenAI-o1
    litellm_params:
      model: o1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
      tpm: 150000
    model_info:
      input_cost_per_token: 0.000015     # $15.00 per 1M input tokens
      cache_read_input_token_cost: 0.0000075   # $7.50 per 1M cached input tokens
      output_cost_per_token: 0.00006     # $60.00 per 1M output tokens
      model_alias: o1
      host_node: openai
      context_window: 128000
      max_output_tokens: 32768
      supports_reasoning: true
      pricing_tier: "premium"

  - model_name: OpenAI-o1-Pro
    litellm_params:
      model: o1-pro
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10
      tpm: 100000
    model_info:
      input_cost_per_token: 0.00015      # $150.00 per 1M input tokens
      output_cost_per_token: 0.0006      # $600.00 per 1M output tokens
      model_alias: o1-Pro
      host_node: openai
      context_window: 128000
      max_output_tokens: 32768
      supports_reasoning: true
      pricing_tier: "enterprise"

  - model_name: OpenAI-o3
    litellm_params:
      model: o3
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
      tpm: 200000
    model_info:
      input_cost_per_token: 0.000002     # $2.00 per 1M input tokens
      cache_read_input_token_cost: 0.0000005   # $0.50 per 1M cached input tokens
      output_cost_per_token: 0.000008    # $8.00 per 1M output tokens
      model_alias: o3
      host_node: openai
      context_window: 128000
      max_output_tokens: 65536
      supports_reasoning: true
      pricing_tier: "premium"

  - model_name: OpenAI-o3-Mini
    litellm_params:
      model: o3-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
      tpm: 300000
    model_info:
      input_cost_per_token: 0.0000011    # $1.10 per 1M input tokens
      cache_read_input_token_cost: 0.00000055  # $0.55 per 1M cached input tokens
      output_cost_per_token: 0.0000044   # $4.40 per 1M output tokens
      model_alias: o3-Mini
      host_node: openai
      context_window: 128000
      max_output_tokens: 65536
      supports_reasoning: true
      pricing_tier: "standard"

  - model_name: OpenAI-o1-Mini
    litellm_params:
      model: o1-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
      tpm: 300000
    model_info:
      input_cost_per_token: 0.0000011    # $1.10 per 1M input tokens
      cache_read_input_token_cost: 0.00000055  # $0.55 per 1M cached input tokens
      output_cost_per_token: 0.0000044   # $4.40 per 1M output tokens
      model_alias: o1-Mini
      host_node: openai
      context_window: 128000
      max_output_tokens: 65536
      supports_reasoning: true
      pricing_tier: "standard"

  # GPT-3.5 Turbo - Cost-effective legacy model
  - model_name: OpenAI-GPT-3.5-Turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.0000005    # $0.50 per 1M input tokens
      output_cost_per_token: 0.0000015   # $1.50 per 1M output tokens
      model_alias: GPT-3.5-Turbo
      host_node: openai
      context_window: 16385
      max_output_tokens: 4096
      supports_function_calling: true
      pricing_tier: "budget"

  # Embedding Models
  - model_name: OpenAI-Text-Embedding-3-Large
    litellm_params:
      model: text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY
      rpm: 5000
      tpm: 5000000
    model_info:
      input_cost_per_token: 0.00000013   # $0.13 per 1M tokens
      model_alias: text-embedding-3-large
      host_node: openai
      mode: embedding
      context_window: 8191
      embedding_dimensions: 3072
      pricing_tier: "standard"

  - model_name: OpenAI-Text-Embedding-3-Small
    litellm_params:
      model: text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY
      rpm: 5000
      tpm: 5000000
    model_info:
      input_cost_per_token: 0.00000002   # $0.02 per 1M tokens
      model_alias: text-embedding-3-small
      host_node: openai
      mode: embedding
      context_window: 8191
      embedding_dimensions: 1536
      pricing_tier: "budget"

  - model_name: OpenAI-Text-Embedding-Ada-002
    litellm_params:
      model: text-embedding-ada-002
      api_key: os.environ/OPENAI_API_KEY
      rpm: 5000
      tpm: 5000000
    model_info:
      input_cost_per_token: 0.0000001    # $0.10 per 1M tokens
      model_alias: text-embedding-ada-002
      host_node: openai
      mode: embedding
      context_window: 8191
      embedding_dimensions: 1536
      pricing_tier: "standard"

  # Audio Models
  - model_name: OpenAI-Whisper-1
    litellm_params:
      model: whisper-1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
    model_info:
      # Note: Whisper pricing is per minute; LiteLLM supports per-second fields
      # $0.006 per minute = $0.0001 per second
      input_cost_per_second: 0.0001      # $0.0001 per second
      model_alias: Whisper-1
      host_node: openai
      mode: audio_transcription
      supported_formats: ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"]
      max_file_size: "25MB"
      pricing_tier: "standard"

  # Text-to-Speech Models
  - model_name: OpenAI-TTS-1-HD
    litellm_params:
      model: tts-1-hd
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
    model_info:
      # Note: TTS pricing is per character
      # $30.00 per 1M characters => $0.00003 per character (output)
      output_cost_per_character: 0.00003
      model_alias: TTS-1-HD
      host_node: openai
      mode: text_to_speech
      voices: ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
      output_formats: ["mp3", "opus", "aac", "flac"]
      pricing_tier: "premium"

  - model_name: OpenAI-TTS-1
    litellm_params:
      model: tts-1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
    model_info:
      # Note: TTS pricing is per character
      # $15.00 per 1M characters => $0.000015 per character (output)
      output_cost_per_character: 0.000015
      model_alias: TTS-1
      host_node: openai
      mode: text_to_speech
      voices: ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
      output_formats: ["mp3", "opus", "aac", "flac"]
      pricing_tier: "standard"

  # Image Generation Models
  - model_name: OpenAI-DALL-E-3
    litellm_params:
      model: dall-e-3
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
    model_info:
      # Note: Image generation pricing is per image, not per token
      # Standard quality 1024x1024: $0.04
      # HD quality 1024x1024: $0.08
      model_alias: DALL-E-3
      host_node: openai
      mode: image_generation
      supported_sizes: ["1024x1024", "1024x1792", "1792x1024"]
      quality_options: ["standard", "hd"]
      pricing_tier: "premium"

  - model_name: OpenAI-DALL-E-2
    litellm_params:
      model: dall-e-2
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
    model_info:
      # Note: Image generation pricing is per image, not per token
      # 1024x1024: $0.02
      model_alias: DALL-E-2
      host_node: openai
      mode: image_generation
      supported_sizes: ["256x256", "512x512", "1024x1024"]
      quality_options: ["standard"]
      pricing_tier: "standard"

  # Additional models from pricing reference
  - model_name: OpenAI-GPT-5-Chat-Latest
    litellm_params:
      model: gpt-5-chat-latest
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.00000125
      cache_read_input_token_cost: 0.000000125
      output_cost_per_token: 0.00001
      model_alias: GPT-5-Chat-Latest
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-4.1-Nano
    litellm_params:
      model: gpt-4.1-nano
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 3000000
    model_info:
      input_cost_per_token: 0.00000010
      cache_read_input_token_cost: 0.000000025
      output_cost_per_token: 0.00000040
      model_alias: GPT-4.1-Nano
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      pricing_tier: "budget"

  - model_name: OpenAI-GPT-Realtime
    litellm_params:
      model: gpt-realtime
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      # Text token pricing
      input_cost_per_token: 0.000004
      cache_read_input_token_cost: 0.0000004
      output_cost_per_token: 0.000016
      # Audio token pricing
      input_cost_per_audio_token: 0.000032
      output_cost_per_audio_token: 0.000064
      model_alias: gpt-realtime
      host_node: openai
      note: "Realtime API - specialized streaming/websocket model; endpoint support may vary."
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-4o-Realtime-Preview
    litellm_params:
      model: gpt-4o-realtime-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.000005
      cache_read_input_token_cost: 0.0000025
      output_cost_per_token: 0.00002
      input_cost_per_audio_token: 0.00004
      output_cost_per_audio_token: 0.00008
      model_alias: gpt-4o-realtime-preview
      host_node: openai
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-4o-Mini-Realtime-Preview
    litellm_params:
      model: gpt-4o-mini-realtime-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 2000
      tpm: 500000
    model_info:
      input_cost_per_token: 0.0000006
      cache_read_input_token_cost: 0.0000003
      output_cost_per_token: 0.0000024
      input_cost_per_audio_token: 0.00001
      output_cost_per_audio_token: 0.00002
      model_alias: gpt-4o-mini-realtime-preview
      host_node: openai
      pricing_tier: "standard"

  - model_name: OpenAI-GPT-Audio
    litellm_params:
      model: gpt-audio
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001
      model_alias: gpt-audio
      host_node: openai
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-4o-Audio-Preview
    litellm_params:
      model: gpt-4o-audio-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001
      input_cost_per_audio_token: 0.00004
      output_cost_per_audio_token: 0.00008
      model_alias: gpt-4o-audio-preview
      host_node: openai
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-4o-Mini-Audio-Preview
    litellm_params:
      model: gpt-4o-mini-audio-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 2000
      tpm: 500000
    model_info:
      input_cost_per_token: 0.00000015
      output_cost_per_token: 0.0000006
      input_cost_per_audio_token: 0.00001
      output_cost_per_audio_token: 0.00002
      model_alias: gpt-4o-mini-audio-preview
      host_node: openai
      pricing_tier: "standard"

  - model_name: OpenAI-o3-Pro
    litellm_params:
      model: o3-pro
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10
      tpm: 100000
    model_info:
      input_cost_per_token: 0.00002
      output_cost_per_token: 0.00008
      model_alias: o3-pro
      host_node: openai
      context_window: 128000
      max_output_tokens: 65536
      supports_reasoning: true
      pricing_tier: "enterprise"

  - model_name: OpenAI-o3-Deep-Research
    litellm_params:
      model: o3-deep-research
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10
      tpm: 100000
    model_info:
      input_cost_per_token: 0.00001
      cache_read_input_token_cost: 0.0000025
      output_cost_per_token: 0.00004
      model_alias: o3-deep-research
      host_node: openai
      context_window: 128000
      max_output_tokens: 65536
      supports_reasoning: true
      pricing_tier: "premium"

  - model_name: OpenAI-o4-Mini
    litellm_params:
      model: o4-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.0000011
      cache_read_input_token_cost: 0.000000275
      output_cost_per_token: 0.0000044
      model_alias: o4-mini
      host_node: openai
      context_window: 128000
      max_output_tokens: 32768
      supports_reasoning: true
      pricing_tier: "standard"

  - model_name: OpenAI-o4-Mini-Deep-Research
    litellm_params:
      model: o4-mini-deep-research
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.000002
      cache_read_input_token_cost: 0.0000005
      output_cost_per_token: 0.000008
      model_alias: o4-mini-deep-research
      host_node: openai
      context_window: 128000
      max_output_tokens: 32768
      supports_reasoning: true
      pricing_tier: "premium"

  - model_name: OpenAI-Codex-Mini-Latest
    litellm_params:
      model: codex-mini-latest
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.0000015
      cache_read_input_token_cost: 0.000000375
      output_cost_per_token: 0.000006
      model_alias: codex-mini-latest
      host_node: openai
      context_window: 128000
      max_output_tokens: 16384
      supports_function_calling: true
      pricing_tier: "standard"

  - model_name: OpenAI-GPT-4o-Mini-Search-Preview
    litellm_params:
      model: gpt-4o-mini-search-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.00000015
      output_cost_per_token: 0.0000006
      model_alias: gpt-4o-mini-search-preview
      host_node: openai
      pricing_tier: "standard"

  - model_name: OpenAI-GPT-4o-Search-Preview
    litellm_params:
      model: gpt-4o-search-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001
      model_alias: gpt-4o-search-preview
      host_node: openai
      pricing_tier: "premium"

  - model_name: OpenAI-Computer-Use-Preview
    litellm_params:
      model: computer-use-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000012
      model_alias: computer-use-preview
      host_node: openai
      pricing_tier: "premium"

  - model_name: OpenAI-GPT-Image-1
    litellm_params:
      model: gpt-image-1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
    model_info:
      # Text token pricing for prompts
      input_cost_per_token: 0.000005
      cache_read_input_token_cost: 0.00000125
      # Image generation is billed per-image depending on size/quality (see docs)
      model_alias: gpt-image-1
      host_node: openai
      mode: image_generation
      supported_sizes: ["1024x1024", "1024x1536", "1536x1024"]
      quality_options: ["low", "medium", "high"]
      pricing_tier: "premium"