# sambanova.yaml
# ðŸš€ SambaNova Model Configurations
# Information verified and updated based on official SambaNova documentation as of August 7, 2025.

model_list:
  # -------------------------------------------
  # Production Models
  # -------------------------------------------

  # SambaNova - Meta Llama 3.1 8B Instruct
  - model_name: SambaNova-Meta-Llama-3.1-8B-Instruct
    litellm_params:
      model: sambanova/Meta-Llama-3.1-8B-Instruct
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 480                   # Official Developer Tier RPM
      max_tokens: 16384          # 16k context window
      input_cost_per_token: 0    # Cost tracking placeholder
      output_cost_per_token: 0   # Pricing is usage-based/enterprise
    model_info:
      host_node: sambanova
      category: "production"
      rpd: 72000                 # Official Developer Tier RPD
      max_output_tokens: 4096    # Max tokens for a single response

  # SambaNova - Meta Llama 3.3 70B Instruct
  - model_name: SambaNova-Meta-Llama-3.3-70B-Instruct
    litellm_params:
      model: sambanova/Meta-Llama-3.3-70B-Instruct
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 120
      max_tokens: 131072         # 128k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "production"
      rpd: 12000
      max_output_tokens: 8192

  # SambaNova - DeepSeek-R1-Distill-Llama-70B
  - model_name: SambaNova-DeepSeek-R1-Distill-Llama-70B
    litellm_params:
      model: sambanova/DeepSeek-R1-Distill-Llama-70B
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 80
      max_tokens: 131072         # 128k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "production"
      rpd: 12000
      max_output_tokens: 8192

  # SambaNova - DeepSeek R1
  - model_name: SambaNova-DeepSeek-R1
    litellm_params:
      model: sambanova/DeepSeek-R1
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 30
      max_tokens: 32768          # 32k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "production"
      rpd: 3000
      max_output_tokens: 4096

  # SambaNova - DeepSeek V3 0324
  - model_name: SambaNova-DeepSeek-V3-0324
    litellm_params:
      model: sambanova/DeepSeek-V3-0324
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 30
      max_tokens: 32768          # 32k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "production"
      rpd: 3000
      max_output_tokens: 4096

  # -------------------------------------------
  # Preview Models
  # -------------------------------------------

  # SambaNova - Whisper Large v3 (Audio Model)
  - model_name: SambaNova-Whisper-Large-v3
    litellm_params:
      model: sambanova/Whisper-Large-v3
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 300
      input_cost_per_token: 0   # Cost for audio models is per-second/minute
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "preview"
      rpd: 45000
      max_file_size_mb: 25      # Provider limit for audio files
      supports_audio: true
      mode: audio_transcription

  # SambaNova - Llama 4 Maverick 17B 128E Instruct
  - model_name: SambaNova-Llama-4-Maverick-17B-128E-Instruct
    litellm_params:
      model: sambanova/Llama-4-Maverick-17B-128E-Instruct
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 40
      max_tokens: 131072         # 128k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "preview"
      rpd: 6000
      max_output_tokens: 8192

  # SambaNova - Llama 3.3 Swallow 70B Instruct v0.4
  - model_name: SambaNova-Llama-3.3-Swallow-70B-Instruct-v0.4
    litellm_params:
      model: sambanova/Llama-3.3-Swallow-70B-Instruct-v0.4
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 40
      max_tokens: 16384          # 16k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "preview"
      rpd: 6000
      max_output_tokens: 4096
  
  # SambaNova - E5 Mistral 7B Instruct (Embedding Model)
  - model_name: SambaNova-E5-Mistral-7B-Instruct
    litellm_params:
      model: sambanova/E5-Mistral-7B-Instruct
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 30
      max_tokens: 4096           # 4k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "preview"
      rpd: 4500
      max_output_tokens: 1024
      supports_embeddings: true
      
  # SambaNova - Qwen3 32B
  - model_name: SambaNova-Qwen3-32B
    litellm_params:
      model: sambanova/Qwen3-32B
      api_base: https://api.sambanova.ai/v1
      api_key: os.environ/SAMBANOVA_API_KEY
      rpm: 20
      max_tokens: 8192           # 8k context window
      input_cost_per_token: 0
      output_cost_per_token: 0
    model_info:
      host_node: sambanova
      category: "preview"
      rpd: 3000
      max_output_tokens: 2048