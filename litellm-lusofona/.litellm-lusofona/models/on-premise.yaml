# üè¢ On-Premise Model Configurations
# Lus√≥fona Internal Infrastructure Models
# 
# These models run on internal Lus√≥fona servers and provide
# local AI capabilities without external dependencies.

model_list:

  # On-Premise Embedding Models via Ollama (pop06)
  # Note: Assuming default Ollama port 11434 on 192.168.80.6. Adjust if different.
  - model_name: embeddings-bge-m3-Lusofona-On-Premise
    litellm_params:
      model: ollama/bge-m3
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: bge-m3
      host_node: 192.168.80.6
      provider: on-premise
      mode: embedding

  - model_name: embeddings-nomic-embed-text-Lusofona-On-Premise
    litellm_params:
      model: ollama/nomic-embed-text
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: nomic-embed-text
      host_node: 192.168.80.6
      provider: on-premise
      mode: embedding

  - model_name: embeddings-embeddinggemma-Lusofona-On-Premise
    litellm_params:
      model: ollama/embeddinggemma
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: embeddinggemma
      host_node: 192.168.80.6
      provider: on-premise
      mode: embedding

  - model_name: embeddings-mxbai-embed-large-Lusofona-On-Premise
    litellm_params:
      model: ollama/mxbai-embed-large
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: mxbai-embed-large
      host_node: 192.168.80.6
      provider: on-premise
      mode: embedding

  - model_name: embeddings-multilingual-e5-base-Lusofona-On-Premise
    litellm_params:
      model: ollama/yxchia/multilingual-e5-base
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: multilingual-e5-base
      host_node: 192.168.80.6
      provider: on-premise
      mode: embedding

  - model_name: embeddings-multilingual-e5-large-Lusofona-On-Premise
    litellm_params:
      model: ollama/zylonai/multilingual-e5-large
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: multilingual-e5-large
      host_node: 192.168.80.6
      provider: on-premise
      mode: embedding

  # On-Premise Reranker Model via Ollama (pop06)
  - model_name: reranker-Qwen3-Reranker-4B-Lusofona-On-Premise
    litellm_params:
      model: ollama/dengcao/Qwen3-Reranker-4B:Q4_K_M
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: Qwen3-Reranker-4B
      host_node: 192.168.80.6
      provider: on-premise
      mode: rerank

  - model_name: reranker-mxbai-rerank-large-v2-Lusofona-On-Premise
    litellm_params:
      model: ollama/rjmalagon/mxbai-rerank-large-v2:1.5b-fp16
      api_base: http://192.168.80.6:11434
      api_key: none
      rpm: 120
    model_info:
      model_alias: mxbai-rerank-large-v2
      host_node: 192.168.80.6
      provider: on-premise
      mode: rerank

  # Internal Infrastructure Model - Qwen3 8B (pop05)
  - model_name: Qwen3-8B-Lusofona-On-Premise
    litellm_params:
      model: openai/Qwen3-8B-Q4_K_M
      api_base: http://192.168.80.5:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: Qwen3-8B-Q4_K_M
      host_node: 192.168.80.5

  # Internal Infrastructure Model - DeepSeek R1 Distill Llama 8B (pop04)
  - model_name: DeepSeek-R1-Distill-Llama-8B-Lusofona-On-Premise
    litellm_params:
      model: openai/DeepSeek-R1-Distill-Llama-8B-Q6_K
      api_base: http://192.168.80.4:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: DeepSeek-R1-Distill-Llama-8B-Q6_K
      host_node: 192.168.80.4

  # Internal Infrastructure Model - Meta Llama 3.1 8B Instruct (pop02)
  - model_name: Meta-Llama-3.1-8B-Instruct-Lusofona-On-Premise
    litellm_params:
      model: openai/Meta-Llama-3.1-8B-Instruct-Q4_K_M
      api_base: http://192.168.80.12:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: Meta-Llama-3.1-8B-Instruct-Q4_K_M
      host_node: 192.168.80.12

  # Internal Infrastructure Model - Gemma 3 4B IT (pop01)
  - model_name: gemma-3-4b-it-Lusofona-On-Premise
    litellm_params:
      model: openai/gemma-3-4b-it-Q8_0
      api_base: http://192.168.80.11:8080
      api_key: none
      rpm: 100000
    model_info:
      model_alias: gemma-3-4b-it-Q8_0
      host_node: 192.168.80.11 