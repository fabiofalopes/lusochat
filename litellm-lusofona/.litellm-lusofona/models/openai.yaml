# openai.yaml
# ðŸ¤– OpenAI Model Configurations - Updated 22-09-2025
# Source: https://platform.openai.com/docs/pricing
# Note: Cached input pricing is represented via `cache_read_input_token_cost` and
#       `cache_creation_input_token_cost` in model_info when applicable.
#
# Web clipping (OpenAI Pricing) - 22-09-2025
# --- BEGIN WEB CLIP ---
# Text tokens (per 1M):
# gpt-5: $1.25 input, $0.125 cached input, $10.00 output
# gpt-5-mini: $0.25 input, $0.025 cached input, $2.00 output
# gpt-5-nano: $0.05 input, $0.005 cached input, $0.40 output
# gpt-4.1: $2.00 input, $0.50 cached input, $8.00 output
# gpt-4.1-mini: $0.40 input, $0.10 cached input, $1.60 output
# gpt-4.1-nano: $0.10 input, $0.025 cached input, $0.40 output
# gpt-4o: $2.50 input, $1.25 cached input, $10.00 output
# gpt-4o-2024-05-13: $5.00 input, - cached input, $15.00 output
# gpt-4o-mini: $0.15 input, $0.075 cached input, $0.60 output
# o1: $15.00 input, $7.50 cached input, $60.00 output
# o1-pro: $150.00 input, - cached input, $600.00 output
# o3: $2.00 input, $0.50 cached input, $8.00 output
# o3-mini: $1.10 input, $0.55 cached input, $4.40 output
# o1-mini: $1.10 input, $0.55 cached input, $4.40 output
# gpt-3.5-turbo: $0.50 input, - cached input, $1.50 output
# Embeddings per 1M: 3-large=$0.13, 3-small=$0.02, ada-002=$0.10
# Image generation: see pricing table (per-image)
# Audio/Other: Whisper=$0.006/min, TTS=$15/$30 per 1M chars
# Built-in tools pricing omitted; refer to source link.
# --- END WEB CLIP ---

model_list:
  # GPT-5 Series - Latest flagship models
  - model_name: OpenAI-GPT-5
    litellm_params:
      model: gpt-5
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.00000125   # $1.25 per 1M input tokens
      cache_read_input_token_cost: 0.000000125   # $0.125 per 1M cached input tokens
      output_cost_per_token: 0.00001     # $10.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  - model_name: OpenAI-GPT-5-Mini
    litellm_params:
      model: gpt-5-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 2000000
    model_info:
      input_cost_per_token: 0.00000025   # $0.25 per 1M input tokens
      cache_read_input_token_cost: 0.000000025  # $0.025 per 1M cached input tokens
      output_cost_per_token: 0.000002    # $2.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  - model_name: OpenAI-GPT-5-Nano
    litellm_params:
      model: gpt-5-nano
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 3000000
    model_info:
      input_cost_per_token: 0.00000005   # $0.05 per 1M input tokens
      cache_read_input_token_cost: 0.000000005  # $0.005 per 1M cached input tokens
      output_cost_per_token: 0.0000004   # $0.40 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  # GPT-4.1 Series - Advanced reasoning models
  - model_name: OpenAI-GPT-4.1
    litellm_params:
      model: gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.000002     # $2.00 per 1M input tokens
      cache_read_input_token_cost: 0.0000005   # $0.50 per 1M cached input tokens
      output_cost_per_token: 0.000008    # $8.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  - model_name: OpenAI-GPT-4.1-Mini
    litellm_params:
      model: gpt-4.1-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1500000
    model_info:
      input_cost_per_token: 0.0000004    # $0.40 per 1M input tokens
      cache_read_input_token_cost: 0.0000001   # $0.10 per 1M cached input tokens
      output_cost_per_token: 0.0000016   # $1.60 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  # GPT-4o Series - Current flagship models
  - model_name: OpenAI-GPT-4o
    litellm_params:
      model: gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.0000025    # $2.50 per 1M input tokens
      cache_read_input_token_cost: 0.00000125  # $1.25 per 1M cached input tokens
      output_cost_per_token: 0.00001     # $10.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  - model_name: OpenAI-GPT-4o-Mini
    litellm_params:
      model: gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 2000000
    model_info:
      input_cost_per_token: 0.00000015   # $0.15 per 1M input tokens
      cache_read_input_token_cost: 0.000000075  # $0.075 per 1M cached input tokens
      output_cost_per_token: 0.0000006   # $0.60 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  # GPT-4o Legacy Version
  - model_name: OpenAI-GPT-4o-2024-05-13
    litellm_params:
      model: gpt-4o-2024-05-13
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 500000
    model_info:
      input_cost_per_token: 0.000005     # $5.00 per 1M input tokens
      output_cost_per_token: 0.000015    # $15.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  # o-Series - Advanced reasoning models
  - model_name: OpenAI-o1
    litellm_params:
      model: o1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
      tpm: 150000
    model_info:
      input_cost_per_token: 0.000015     # $15.00 per 1M input tokens
      cache_read_input_token_cost: 0.0000075   # $7.50 per 1M cached input tokens
      output_cost_per_token: 0.00006     # $60.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 32768
      mode: chat

  - model_name: OpenAI-o1-Pro
    litellm_params:
      model: o1-pro
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10
      tpm: 100000
    model_info:
      input_cost_per_token: 0.00015      # $150.00 per 1M input tokens
      output_cost_per_token: 0.0006      # $600.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 32768
      mode: chat

  - model_name: OpenAI-o3
    litellm_params:
      model: o3
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
      tpm: 200000
    model_info:
      input_cost_per_token: 0.000002     # $2.00 per 1M input tokens
      cache_read_input_token_cost: 0.0000005   # $0.50 per 1M cached input tokens
      output_cost_per_token: 0.000008    # $8.00 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 65536
      mode: chat

  - model_name: OpenAI-o3-Mini
    litellm_params:
      model: o3-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
      tpm: 300000
    model_info:
      input_cost_per_token: 0.0000011    # $1.10 per 1M input tokens
      cache_read_input_token_cost: 0.00000055  # $0.55 per 1M cached input tokens
      output_cost_per_token: 0.0000044   # $4.40 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 65536
      mode: chat

  - model_name: OpenAI-o1-Mini
    litellm_params:
      model: o1-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
      tpm: 300000
    model_info:
      input_cost_per_token: 0.0000011    # $1.10 per 1M input tokens
      cache_read_input_token_cost: 0.00000055  # $0.55 per 1M cached input tokens
      output_cost_per_token: 0.0000044   # $4.40 per 1M output tokens
      max_tokens: 128000
      max_output_tokens: 65536
      mode: chat

  # GPT-3.5 Turbo - Cost-effective legacy model
  - model_name: OpenAI-GPT-3.5-Turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.0000005    # $0.50 per 1M input tokens
      output_cost_per_token: 0.0000015   # $1.50 per 1M output tokens
      max_tokens: 16385
      max_output_tokens: 4096
      supports_function_calling: true
      mode: chat

  # Embedding Models
  - model_name: OpenAI-Text-Embedding-3-Large
    litellm_params:
      model: text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY
      rpm: 5000
      tpm: 5000000
    model_info:
      input_cost_per_token: 0.00000013   # $0.13 per 1M tokens
      mode: embedding
      max_tokens: 8191
      output_vector_size: 3072

  - model_name: OpenAI-Text-Embedding-3-Small
    litellm_params:
      model: text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY
      rpm: 5000
      tpm: 5000000
    model_info:
      input_cost_per_token: 0.00000002   # $0.02 per 1M tokens
      mode: embedding
      max_tokens: 8191
      output_vector_size: 1536

  - model_name: OpenAI-Text-Embedding-Ada-002
    litellm_params:
      model: text-embedding-ada-002
      api_key: os.environ/OPENAI_API_KEY
      rpm: 5000
      tpm: 5000000
    model_info:
      input_cost_per_token: 0.0000001    # $0.10 per 1M tokens
      mode: embedding
      max_tokens: 8191
      output_vector_size: 1536

  # Audio Models
  - model_name: OpenAI-Whisper-1
    litellm_params:
      model: whisper-1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
    model_info:
      # Note: Whisper pricing is per minute; LiteLLM supports per-second fields
      # $0.006 per minute = $0.0001 per second
      input_cost_per_second: 0.0001      # $0.0001 per second
      mode: audio_transcription
      max_file_size_mb: 25

  # Text-to-Speech Models
  - model_name: OpenAI-TTS-1-HD
    litellm_params:
      model: tts-1-hd
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
    model_info:
      # Note: TTS pricing is per character
      # $30.00 per 1M characters => $0.00003 per character (output)
      input_cost_per_character: 0.00003
      mode: text_to_speech

  - model_name: OpenAI-TTS-1
    litellm_params:
      model: tts-1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 20
    model_info:
      # Note: TTS pricing is per character
      # $15.00 per 1M characters => $0.000015 per character (output)
      input_cost_per_character: 0.000015
      mode: text_to_speech

  # Image Generation Models
  - model_name: OpenAI-DALL-E-3
    litellm_params:
      model: dall-e-3
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
    model_info:
      # Note: Image generation pricing is per image, not per token
      # Standard quality 1024x1024: $0.04
      # HD quality 1024x1024: $0.08
      mode: image_generation
      output_cost_per_image: 0.04

  - model_name: OpenAI-DALL-E-2
    litellm_params:
      model: dall-e-2
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50
    model_info:
      # Note: Image generation pricing is per image, not per token
      # 1024x1024: $0.02
      mode: image_generation
      output_cost_per_image: 0.02

  # Additional models from pricing reference
  - model_name: OpenAI-GPT-5-Chat-Latest
    litellm_params:
      model: gpt-5-chat-latest
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.00000125
      cache_read_input_token_cost: 0.000000125
      output_cost_per_token: 0.00001
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  - model_name: OpenAI-GPT-4.1-Nano
    litellm_params:
      model: gpt-4.1-nano
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 3000000
    model_info:
      input_cost_per_token: 0.00000010
      cache_read_input_token_cost: 0.000000025
      output_cost_per_token: 0.00000040
      max_tokens: 128000
      max_output_tokens: 16384
      supports_vision: true
      supports_function_calling: true
      mode: chat

  - model_name: OpenAI-GPT-Realtime
    litellm_params:
      model: gpt-realtime
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      # Text token pricing
      input_cost_per_token: 0.000004
      cache_read_input_token_cost: 0.0000004
      output_cost_per_token: 0.000016
      mode: chat

  - model_name: OpenAI-GPT-4o-Realtime-Preview
    litellm_params:
      model: gpt-4o-realtime-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.000005
      cache_read_input_token_cost: 0.0000025
      output_cost_per_token: 0.00002
      mode: chat

  - model_name: OpenAI-GPT-4o-Mini-Realtime-Preview
    litellm_params:
      model: gpt-4o-mini-realtime-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 2000
      tpm: 500000
    model_info:
      input_cost_per_token: 0.0000006
      cache_read_input_token_cost: 0.0000003
      output_cost_per_token: 0.0000024
      mode: chat

  - model_name: OpenAI-GPT-Audio
    litellm_params:
      model: gpt-audio
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001
      mode: chat

  - model_name: OpenAI-GPT-4o-Audio-Preview
    litellm_params:
      model: gpt-4o-audio-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001
      mode: chat

  - model_name: OpenAI-GPT-4o-Mini-Audio-Preview
    litellm_params:
      model: gpt-4o-mini-audio-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 2000
      tpm: 500000
    model_info:
      input_cost_per_token: 0.00000015
      output_cost_per_token: 0.0000006
      mode: chat

  - model_name: OpenAI-o3-Pro
    litellm_params:
      model: o3-pro
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10
      tpm: 100000
    model_info:
      input_cost_per_token: 0.00002
      output_cost_per_token: 0.00008
      max_tokens: 128000
      max_output_tokens: 65536
      mode: chat

  - model_name: OpenAI-o3-Deep-Research
    litellm_params:
      model: o3-deep-research
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10
      tpm: 100000
    model_info:
      input_cost_per_token: 0.00001
      cache_read_input_token_cost: 0.0000025
      output_cost_per_token: 0.00004
      max_tokens: 128000
      max_output_tokens: 65536
      mode: chat

  - model_name: OpenAI-o4-Mini
    litellm_params:
      model: o4-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.0000011
      cache_read_input_token_cost: 0.000000275
      output_cost_per_token: 0.0000044
      max_tokens: 128000
      max_output_tokens: 32768
      mode: chat

  - model_name: OpenAI-o4-Mini-Deep-Research
    litellm_params:
      model: o4-mini-deep-research
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.000002
      cache_read_input_token_cost: 0.0000005
      output_cost_per_token: 0.000008
      max_tokens: 128000
      max_output_tokens: 32768
      mode: chat

  - model_name: OpenAI-Codex-Mini-Latest
    litellm_params:
      model: codex-mini-latest
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.0000015
      cache_read_input_token_cost: 0.000000375
      output_cost_per_token: 0.000006
      max_tokens: 128000
      max_output_tokens: 16384
      supports_function_calling: true
      mode: chat

  - model_name: OpenAI-GPT-4o-Mini-Search-Preview
    litellm_params:
      model: gpt-4o-mini-search-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 1000000
    model_info:
      input_cost_per_token: 0.00000015
      output_cost_per_token: 0.0000006
      mode: chat

  - model_name: OpenAI-GPT-4o-Search-Preview
    litellm_params:
      model: gpt-4o-search-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10000
      tpm: 800000
    model_info:
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001
      mode: chat

  - model_name: OpenAI-Computer-Use-Preview
    litellm_params:
      model: computer-use-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
      tpm: 200000
    model_info:
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000012
      mode: chat

  - model_name: OpenAI-GPT-Image-1
    litellm_params:
      model: gpt-image-1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 1000
    model_info:
      # Text token pricing for prompts
      input_cost_per_token: 0.000005
      cache_read_input_token_cost: 0.00000125
      # Image generation is billed per-image depending on size/quality (see docs)
      mode: image_generation
      output_cost_per_image: 0.042